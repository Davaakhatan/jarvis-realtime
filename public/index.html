<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Jarvis Voice Assistant</title>
  <style>
    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }
    body {
      font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
      background: #0a0a0f;
      color: #e0e0e0;
      min-height: 100vh;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 2rem;
    }
    h1 {
      color: #00d4ff;
      margin-bottom: 0.5rem;
    }
    .subtitle {
      color: #666;
      margin-bottom: 2rem;
    }
    .status {
      display: flex;
      align-items: center;
      gap: 0.5rem;
      margin-bottom: 1rem;
      padding: 0.5rem 1rem;
      background: #1a1a2e;
      border-radius: 20px;
    }
    .status-dot {
      width: 10px;
      height: 10px;
      border-radius: 50%;
      background: #ff4444;
    }
    .status-dot.connected {
      background: #44ff44;
    }
    .voice-button {
      width: 120px;
      height: 120px;
      border-radius: 50%;
      border: 3px solid #00d4ff;
      background: linear-gradient(145deg, #1a1a2e, #0a0a1a);
      color: #00d4ff;
      font-size: 2rem;
      cursor: pointer;
      transition: all 0.3s;
      display: flex;
      align-items: center;
      justify-content: center;
      margin: 2rem 0;
    }
    .voice-button:hover {
      transform: scale(1.05);
      box-shadow: 0 0 30px rgba(0, 212, 255, 0.3);
    }
    .voice-button.recording {
      background: linear-gradient(145deg, #2a1a2e, #1a0a1a);
      border-color: #ff4444;
      animation: pulse 1.5s infinite;
    }
    .voice-button.processing {
      border-color: #ffaa00;
    }
    .voice-button.speaking {
      border-color: #44ff44;
    }
    @keyframes pulse {
      0%, 100% { box-shadow: 0 0 20px rgba(255, 68, 68, 0.4); }
      50% { box-shadow: 0 0 40px rgba(255, 68, 68, 0.6); }
    }
    .state-label {
      font-size: 0.9rem;
      color: #888;
      margin-bottom: 2rem;
      text-transform: uppercase;
      letter-spacing: 2px;
    }
    .conversation {
      width: 100%;
      max-width: 600px;
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      background: #12121a;
      border-radius: 12px;
      margin-bottom: 1rem;
    }
    .message {
      padding: 1rem;
      margin-bottom: 1rem;
      border-radius: 12px;
      max-width: 85%;
    }
    .message.user {
      background: #1a2a3a;
      margin-left: auto;
      border-bottom-right-radius: 4px;
    }
    .message.assistant {
      background: #1a1a2e;
      border-bottom-left-radius: 4px;
    }
    .message .role {
      font-size: 0.75rem;
      color: #666;
      margin-bottom: 0.25rem;
      text-transform: uppercase;
    }
    .message.user .role {
      color: #00d4ff;
    }
    .message.assistant .role {
      color: #44ff44;
    }
    .interrupt-btn {
      position: fixed;
      bottom: 2rem;
      right: 2rem;
      padding: 1rem 2rem;
      background: #ff4444;
      color: white;
      border: none;
      border-radius: 8px;
      cursor: pointer;
      font-size: 1rem;
      display: none;
    }
    .interrupt-btn.visible {
      display: block;
    }
    .transcript {
      font-style: italic;
      color: #888;
      padding: 0.5rem;
      text-align: center;
    }
    .mode-toggle {
      display: flex;
      align-items: center;
      gap: 0.75rem;
      margin-bottom: 1rem;
      padding: 0.5rem 1rem;
      background: #1a1a2e;
      border-radius: 20px;
    }
    .toggle-switch {
      position: relative;
      width: 50px;
      height: 26px;
    }
    .toggle-switch input {
      opacity: 0;
      width: 0;
      height: 0;
    }
    .toggle-slider {
      position: absolute;
      cursor: pointer;
      top: 0;
      left: 0;
      right: 0;
      bottom: 0;
      background: #333;
      transition: 0.3s;
      border-radius: 26px;
    }
    .toggle-slider:before {
      position: absolute;
      content: "";
      height: 20px;
      width: 20px;
      left: 3px;
      bottom: 3px;
      background: white;
      transition: 0.3s;
      border-radius: 50%;
    }
    .toggle-switch input:checked + .toggle-slider {
      background: #00d4ff;
    }
    .toggle-switch input:checked + .toggle-slider:before {
      transform: translateX(24px);
    }
    .voice-button.listening-passive {
      border-color: #666;
      animation: pulse-passive 3s infinite;
    }
    @keyframes pulse-passive {
      0%, 100% { box-shadow: 0 0 10px rgba(102, 102, 102, 0.2); }
      50% { box-shadow: 0 0 20px rgba(102, 102, 102, 0.4); }
    }
    .wake-indicator {
      font-size: 0.8rem;
      color: #00d4ff;
      margin-top: -1rem;
      margin-bottom: 1rem;
      opacity: 0;
      transition: opacity 0.3s;
    }
    .wake-indicator.visible {
      opacity: 1;
    }
  </style>
</head>
<body>
  <h1>JARVIS</h1>
  <p class="subtitle">Real-time Voice Assistant</p>
  <p class="subtitle" style="font-size: 0.75rem; margin-top: -1rem;">Wake: "Jarvis" | Interrupt: "Stop", "Cancel", "Wait"</p>

  <div class="mode-toggle">
    <label class="toggle-switch">
      <input type="checkbox" id="alwaysListenToggle">
      <span class="toggle-slider"></span>
    </label>
    <span id="modeLabel">Push-to-talk</span>
  </div>

  <div class="status">
    <div class="status-dot" id="statusDot"></div>
    <span id="statusText">Disconnected</span>
  </div>

  <button class="voice-button" id="voiceBtn">üé§</button>
  <div class="wake-indicator" id="wakeIndicator">üéØ Wake word detected!</div>
  <div class="state-label" id="stateLabel">Press to speak</div>

  <div class="conversation" id="conversation"></div>

  <div class="transcript" id="transcript"></div>

  <button class="interrupt-btn" id="interruptBtn">‚èπ Interrupt</button>

  <script>
    const WS_URL = 'ws://localhost:3001';
    let ws = null;
    let mediaRecorder = null;
    let audioContext = null;
    let isRecording = false;
    let sessionId = null;
    let alwaysListening = false;
    let passiveStream = null;
    let passiveContext = null;
    let speechRecognition = null;
    let wakeWordTimeout = null;

    const voiceBtn = document.getElementById('voiceBtn');
    const stateLabel = document.getElementById('stateLabel');
    const statusDot = document.getElementById('statusDot');
    const statusText = document.getElementById('statusText');
    const conversation = document.getElementById('conversation');
    const transcript = document.getElementById('transcript');
    const interruptBtn = document.getElementById('interruptBtn');
    const alwaysListenToggle = document.getElementById('alwaysListenToggle');
    const modeLabel = document.getElementById('modeLabel');
    const wakeIndicator = document.getElementById('wakeIndicator');

    function connect() {
      ws = new WebSocket(WS_URL);

      ws.onopen = () => {
        statusDot.classList.add('connected');
        statusText.textContent = 'Connected';
        stateLabel.textContent = 'Press to speak';
      };

      ws.onclose = () => {
        statusDot.classList.remove('connected');
        statusText.textContent = 'Disconnected';
        stateLabel.textContent = 'Reconnecting...';
        setTimeout(connect, 3000);
      };

      ws.onerror = (error) => {
        console.error('WebSocket error:', error);
      };

      ws.onmessage = (event) => {
        const data = JSON.parse(event.data);
        handleMessage(data);
      };
    }

    function handleMessage(data) {
      console.log('Received:', data);

      switch (data.type) {
        case 'session.created':
          sessionId = data.sessionId;
          console.log('Session created:', sessionId);
          break;

        case 'transcript.partial':
          transcript.textContent = data.payload?.text || '';
          break;

        case 'transcript.final':
          transcript.textContent = '';
          addMessage('user', data.payload?.text || '');
          break;

        case 'llm.chunk':
          updateAssistantMessage(data.payload?.text || '');
          break;

        case 'llm.end':
          finalizeAssistantMessage();
          break;

        case 'tts.start':
          voiceBtn.className = 'voice-button speaking';
          stateLabel.textContent = 'Speaking...';
          interruptBtn.classList.add('visible');
          break;

        case 'tts.chunk':
          // Play audio chunk
          if (data.payload?.audio) {
            playAudio(data.payload.audio);
          }
          break;

        case 'tts.end':
          interruptBtn.classList.remove('visible');
          if (alwaysListening) {
            startPassiveListening();
          } else {
            voiceBtn.className = 'voice-button';
            stateLabel.textContent = 'Press to speak';
          }
          break;

        case 'session.interrupt':
          interruptBtn.classList.remove('visible');
          if (alwaysListening) {
            startPassiveListening();
          } else {
            voiceBtn.className = 'voice-button';
            stateLabel.textContent = 'Interrupted - Press to speak';
          }
          break;

        case 'session.state_change':
          console.log('State changed:', data.payload);
          break;

        case 'error':
          console.error('Error:', data.payload);
          stateLabel.textContent = 'Error: ' + (data.payload?.message || 'Unknown');
          break;
      }
    }

    let currentAssistantMessage = '';
    let assistantMessageEl = null;

    function addMessage(role, content) {
      const div = document.createElement('div');
      div.className = `message ${role}`;
      div.innerHTML = `<div class="role">${role}</div><div class="content">${content}</div>`;
      conversation.appendChild(div);
      conversation.scrollTop = conversation.scrollHeight;
      return div;
    }

    function updateAssistantMessage(chunk) {
      if (!assistantMessageEl) {
        assistantMessageEl = addMessage('assistant', '');
        currentAssistantMessage = '';
      }
      currentAssistantMessage += chunk;
      assistantMessageEl.querySelector('.content').textContent = currentAssistantMessage;
      conversation.scrollTop = conversation.scrollHeight;
    }

    function finalizeAssistantMessage() {
      assistantMessageEl = null;
      currentAssistantMessage = '';
    }

    async function startRecording() {
      try {
        const stream = await navigator.mediaDevices.getUserMedia({
          audio: {
            sampleRate: 16000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          }
        });

        audioContext = new AudioContext({ sampleRate: 16000 });
        const source = audioContext.createMediaStreamSource(stream);
        const processor = audioContext.createScriptProcessor(4096, 1, 1);

        processor.onaudioprocess = (e) => {
          if (!isRecording) return;

          const inputData = e.inputBuffer.getChannelData(0);
          const pcmData = new Int16Array(inputData.length);

          for (let i = 0; i < inputData.length; i++) {
            pcmData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32768));
          }

          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(pcmData.buffer);
          }
        };

        source.connect(processor);
        processor.connect(audioContext.destination);

        isRecording = true;
        voiceBtn.className = 'voice-button recording';
        stateLabel.textContent = 'Listening...';

      } catch (err) {
        console.error('Error accessing microphone:', err);
        stateLabel.textContent = 'Microphone access denied';
      }
    }

    function stopRecording() {
      isRecording = false;

      if (audioContext) {
        audioContext.close();
        audioContext = null;
      }

      voiceBtn.className = 'voice-button processing';
      stateLabel.textContent = 'Processing...';

      // Send end of audio signal
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'audio.end' }));
      }

      // Resume passive listening after a delay if in always-listening mode
      if (alwaysListening) {
        setTimeout(() => {
          if (alwaysListening && !isRecording) {
            startPassiveListening();
          }
        }, 1000);
      }
    }

    function playAudio(base64Audio) {
      // TODO: Implement audio playback from base64/buffer
      console.log('Audio chunk received');
    }

    voiceBtn.addEventListener('mousedown', () => {
      if (!isRecording && ws && ws.readyState === WebSocket.OPEN) {
        startRecording();
      }
    });

    voiceBtn.addEventListener('mouseup', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    voiceBtn.addEventListener('mouseleave', () => {
      if (isRecording) {
        stopRecording();
      }
    });

    interruptBtn.addEventListener('click', () => {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'interrupt' }));
      }
    });

    // Keyboard shortcut: Space to talk
    document.addEventListener('keydown', (e) => {
      if (e.code === 'Space' && !e.repeat && !isRecording) {
        e.preventDefault();
        if (ws && ws.readyState === WebSocket.OPEN) {
          startRecording();
        }
      }
    });

    document.addEventListener('keyup', (e) => {
      if (e.code === 'Space' && isRecording) {
        e.preventDefault();
        stopRecording();
      }
    });

    // Always-listening mode with wake word detection
    function startPassiveListening() {
      if (speechRecognition) {
        speechRecognition.stop();
      }

      // Use Web Speech API for wake word detection (lightweight)
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      if (!SpeechRecognition) {
        console.warn('Speech Recognition not supported');
        stateLabel.textContent = 'Wake word not supported in this browser';
        return;
      }

      speechRecognition = new SpeechRecognition();
      speechRecognition.continuous = true;
      speechRecognition.interimResults = true;
      speechRecognition.lang = 'en-US';

      speechRecognition.onresult = (event) => {
        const last = event.results.length - 1;
        const transcript = event.results[last][0].transcript.toLowerCase();

        // Check for wake words
        const wakeWords = ['jarvis', 'hey jarvis', 'ok jarvis', 'hey travis', 'travis'];
        const hasWakeWord = wakeWords.some(word => transcript.includes(word));

        if (hasWakeWord && !isRecording) {
          console.log('Wake word detected:', transcript);
          onWakeWordDetected(transcript);
        }

        // Check for interrupt words during response
        const interruptWords = ['stop', 'cancel', 'wait', 'hold on', 'pause', 'never mind'];
        const hasInterrupt = interruptWords.some(word => transcript.includes(word));

        if (hasInterrupt && interruptBtn.classList.contains('visible')) {
          console.log('Interrupt word detected:', transcript);
          if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send(JSON.stringify({ type: 'interrupt' }));
          }
        }
      };

      speechRecognition.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        if (event.error === 'not-allowed') {
          stateLabel.textContent = 'Microphone access denied';
          alwaysListenToggle.checked = false;
          alwaysListening = false;
          modeLabel.textContent = 'Push-to-talk';
        }
      };

      speechRecognition.onend = () => {
        // Restart if still in always-listening mode
        if (alwaysListening && !isRecording) {
          setTimeout(() => {
            if (alwaysListening && !isRecording) {
              speechRecognition.start();
            }
          }, 100);
        }
      };

      try {
        speechRecognition.start();
        voiceBtn.className = 'voice-button listening-passive';
        stateLabel.textContent = 'Listening for "Jarvis"...';
        console.log('Passive listening started');
      } catch (err) {
        console.error('Failed to start speech recognition:', err);
      }
    }

    function stopPassiveListening() {
      if (speechRecognition) {
        speechRecognition.stop();
        speechRecognition = null;
      }
      if (!isRecording) {
        voiceBtn.className = 'voice-button';
        stateLabel.textContent = 'Press to speak';
      }
    }

    function onWakeWordDetected(transcript) {
      // Show indicator
      wakeIndicator.classList.add('visible');
      clearTimeout(wakeWordTimeout);
      wakeWordTimeout = setTimeout(() => {
        wakeIndicator.classList.remove('visible');
      }, 2000);

      // Stop passive listening temporarily
      if (speechRecognition) {
        speechRecognition.stop();
      }

      // Extract command after wake word (if any)
      let command = transcript;
      const wakeWords = ['hey jarvis', 'ok jarvis', 'jarvis', 'hey travis', 'travis'];
      for (const word of wakeWords) {
        const idx = command.indexOf(word);
        if (idx !== -1) {
          command = command.substring(idx + word.length).trim();
          break;
        }
      }

      // If there's a command after the wake word, send it directly
      if (command.length > 3) {
        console.log('Command after wake word:', command);
        addMessage('user', command);
        if (ws && ws.readyState === WebSocket.OPEN) {
          ws.send(JSON.stringify({ type: 'transcript', text: command, isFinal: true }));
        }
        voiceBtn.className = 'voice-button processing';
        stateLabel.textContent = 'Processing...';

        // Resume passive listening after a delay
        setTimeout(() => {
          if (alwaysListening && !isRecording) {
            startPassiveListening();
          }
        }, 1000);
      } else {
        // No command, start active recording
        startRecording();

        // Auto-stop after silence (5 seconds)
        setTimeout(() => {
          if (isRecording) {
            stopRecording();
          }
        }, 5000);
      }
    }

    // Toggle handler
    alwaysListenToggle.addEventListener('change', (e) => {
      alwaysListening = e.target.checked;
      modeLabel.textContent = alwaysListening ? 'Always listening' : 'Push-to-talk';

      if (alwaysListening) {
        startPassiveListening();
      } else {
        stopPassiveListening();
      }
    });

    // Connect on load
    connect();
  </script>
</body>
</html>
